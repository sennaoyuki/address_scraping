from flask import Flask, render_template, request, jsonify
import requests
from bs4 import BeautifulSoup
import os
import time
from urllib.parse import urljoin, urlparse
import base64
import io

app = Flask(__name__)

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return """
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ã‚¯ãƒªãƒ‹ãƒƒã‚¯ç”»åƒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼</title>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.0/font/bootstrap-icons.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row justify-content-center">
                <div class="col-lg-8">
                    <div class="card">
                        <div class="card-body">
                            <h1 class="card-title text-center">ğŸ¥ ã‚¯ãƒªãƒ‹ãƒƒã‚¯ç”»åƒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼</h1>
                            
                            <div class="alert alert-success mt-4">
                                <h6><i class="bi bi-check-circle"></i> Vercelå¯¾å¿œç‰ˆ</h6>
                                <p class="mb-0">ç”»åƒURLã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã™ï¼ˆå®Ÿè¡Œæ™‚é–“åˆ¶é™: 10ç§’ï¼‰</p>
                            </div>

                            <form id="scrapeForm">
                                <div class="mb-3">
                                    <label for="urlInput" class="form-label">
                                        <i class="bi bi-link-45deg"></i> ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒšãƒ¼ã‚¸ã®URL
                                    </label>
                                    <input type="url" class="form-control" id="urlInput" 
                                           placeholder="https://dioclinic.jp/clinic/" required>
                                </div>
                                
                                <button type="submit" class="btn btn-primary w-100" id="submitBtn">
                                    <i class="bi bi-search"></i> ç”»åƒURLã‚’æ¤œç´¢
                                </button>
                            </form>

                            <div id="resultArea" class="mt-4" style="display: none;">
                                <div class="alert alert-success">
                                    <h5><i class="bi bi-check-circle"></i> æ¤œç´¢å®Œäº†</h5>
                                    <div id="resultContent"></div>
                                </div>
                            </div>

                            <div id="errorArea" class="mt-4" style="display: none;">
                                <div class="alert alert-danger">
                                    <h5><i class="bi bi-exclamation-triangle"></i> ã‚¨ãƒ©ãƒ¼</h5>
                                    <div id="errorContent"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <script>
            document.getElementById('scrapeForm').addEventListener('submit', async (e) => {
                e.preventDefault();
                
                const url = document.getElementById('urlInput').value;
                const submitBtn = document.getElementById('submitBtn');
                const resultArea = document.getElementById('resultArea');
                const errorArea = document.getElementById('errorArea');
                
                // UIãƒªã‚»ãƒƒãƒˆ
                resultArea.style.display = 'none';
                errorArea.style.display = 'none';
                
                // ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–
                submitBtn.disabled = true;
                submitBtn.innerHTML = '<span class="spinner-border spinner-border-sm me-2"></span>æ¤œç´¢ä¸­...';
                
                try {
                    const response = await fetch('/api/scrape', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ url: url })
                    });
                    
                    const data = await response.json();
                    
                    if (data.success) {
                        document.getElementById('resultContent').innerHTML = 
                            `<p><strong>${data.count}æš</strong>ã®ç”»åƒURLã‚’ç™ºè¦‹ã—ã¾ã—ãŸï¼š</p>
                             <div class="mb-3">
                                 <button class="btn btn-success btn-sm" id="downloadAllBtn">
                                     <i class="bi bi-download"></i> å…¨ç”»åƒã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå€‹åˆ¥ï¼‰
                                 </button>
                                 <button class="btn btn-primary btn-sm ms-2" id="downloadZipBtn">
                                     <i class="bi bi-file-earmark-zip"></i> ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                                 </button>
                             </div>
                             <div style="max-height: 300px; overflow-y: auto;">
                                 ${data.urls.map((url, i) => 
                                    `<div class="mb-2 d-flex align-items-center">
                                        <small class="text-muted me-2">${i+1}.</small>
                                        <a href="${url}" target="_blank" class="text-break flex-grow-1">${url}</a>
                                        <button class="btn btn-outline-primary btn-sm ms-2" onclick="downloadImage('${url}', '${i+1}')">
                                            <i class="bi bi-download"></i>
                                        </button>
                                     </div>`
                                 ).join('')}
                             </div>`;
                        resultArea.style.display = 'block';
                        
                        // ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¿½åŠ 
                        document.getElementById('downloadAllBtn').addEventListener('click', function() {
                            downloadAllImages(data.urls);
                        });
                        
                        // ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¿½åŠ 
                        document.getElementById('downloadZipBtn').addEventListener('click', function() {
                            downloadAsZip(data.urls, url);
                        });
                    } else {
                        document.getElementById('errorContent').textContent = data.error;
                        errorArea.style.display = 'block';
                    }
                } catch (error) {
                    document.getElementById('errorContent').textContent = 'ã‚µãƒ¼ãƒãƒ¼ã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚';
                    errorArea.style.display = 'block';
                } finally {
                    submitBtn.disabled = false;
                    submitBtn.innerHTML = '<i class="bi bi-search"></i> ç”»åƒURLã‚’æ¤œç´¢';
                }
            });

            // å€‹åˆ¥ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            window.downloadImage = async function(imageUrl, index) {
                try {
                    // ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ç”»åƒã‚’å–å¾—
                    const response = await fetch('/api/proxy-image', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ url: imageUrl })
                    });
                    
                    const data = await response.json();
                    
                    if (!data.success) {
                        throw new Error(data.error);
                    }
                    
                    // Base64ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    const a = document.createElement('a');
                    a.href = data.data;
                    
                    // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                    const extension = imageUrl.split('.').pop() || 'jpg';
                    a.download = `clinic_image_${index.padStart(3, '0')}.${extension}`;
                    
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                } catch (error) {
                    alert('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: ' + error.message);
                }
            };

            // å…¨ç”»åƒä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            window.downloadAllImages = async function(urls) {
                if (!urls || urls.length === 0) return;
                
                const button = document.getElementById('downloadAllBtn');
                const originalText = button.innerHTML;
                button.disabled = true;
                let downloaded = 0;
                
                for (let i = 0; i < urls.length; i++) {
                    button.innerHTML = `<span class="spinner-border spinner-border-sm me-2"></span>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (${downloaded + 1}/${urls.length})`;
                    
                    try {
                        await downloadImage(urls[i], (i + 1).toString());
                        downloaded++;
                        // 1ç§’é–“éš”ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        if (i < urls.length - 1) {
                            await new Promise(resolve => setTimeout(resolve, 1000));
                        }
                    } catch (error) {
                        console.error('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:', error);
                    }
                }
                
                button.disabled = false;
                button.innerHTML = originalText;
                alert(`${downloaded}æšã®ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼`);
            };

            // ZIPå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            window.downloadAsZip = async function(urls, siteUrl) {
                if (!urls || urls.length === 0) return;
                
                const button = document.getElementById('downloadZipBtn');
                const originalText = button.innerHTML;
                button.disabled = true;
                
                const zip = new JSZip();
                let downloaded = 0;
                
                for (let i = 0; i < urls.length; i++) {
                    button.innerHTML = `<span class="spinner-border spinner-border-sm me-2"></span>ZIPä½œæˆä¸­... (${downloaded + 1}/${urls.length})`;
                    
                    try {
                        // ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ç”»åƒã‚’å–å¾—
                        const response = await fetch('/api/proxy-image', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ url: urls[i] })
                        });
                        
                        const data = await response.json();
                        
                        if (data.success) {
                            // Base64ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                            const base64Data = data.data.split(',')[1];
                            const extension = urls[i].split('.').pop() || 'jpg';
                            const filename = `clinic_image_${(i + 1).toString().padStart(3, '0')}.${extension}`;
                            
                            // ZIPã«è¿½åŠ 
                            zip.file(filename, base64Data, {base64: true});
                            downloaded++;
                        }
                    } catch (error) {
                        console.error('ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼:', error);
                    }
                }
                
                // ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
                button.innerHTML = `<span class="spinner-border spinner-border-sm me-2"></span>ZIPãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...`;
                
                try {
                    const content = await zip.generateAsync({type: 'blob'});
                    
                    // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    const a = document.createElement('a');
                    const url = window.URL.createObjectURL(content);
                    a.href = url;
                    
                    // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’ä½¿ç”¨ï¼‰
                    const domain = new URL(siteUrl).hostname.replace('www.', '');
                    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
                    a.download = `${domain}_images_${timestamp}.zip`;
                    
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    window.URL.revokeObjectURL(url);
                    
                    alert(`${downloaded}æšã®ç”»åƒã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼`);
                } catch (error) {
                    alert('ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ' + error.message);
                }
                
                button.disabled = false;
                button.innerHTML = originalText;
            };
        </script>
    </body>
    </html>
    """

@app.route('/api/scrape', methods=['POST'])
def scrape():
    """ç”»åƒURLã‚’æ¤œç´¢"""
    try:
        data = request.json
        url = data.get('url')
        
        if not url:
            return jsonify({'success': False, 'error': 'URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'})
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        response = requests.get(url, headers=headers, timeout=8)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ç”»åƒURLã‚’æ¤œå‡º
        image_urls = []
        domain = urlparse(url).netloc
        
        # ãƒªã‚¼ã‚¯ãƒªãƒ‹ãƒƒã‚¯å°‚ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        if 'rizeclinic' in domain:
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if '/assets/img/locations/' in src and 'img_gallery01.jpg' in src:
                    absolute_url = urljoin(url, src)
                    image_urls.append(absolute_url)
            
            # è¿½åŠ ãƒ‘ã‚¿ãƒ¼ãƒ³: åº—èˆ—ç”»åƒ
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if '/assets/img/locations/' in src and any(x in src for x in ['gallery', 'clinic', 'store']):
                    absolute_url = urljoin(url, src)
                    image_urls.append(absolute_url)
        
        # DR.ã‚¹ã‚­ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯å°‚ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'drskinclinic' in domain:
            for img in soup.select('img[alt$="é™¢"]'):
                if img.get('src'):
                    absolute_url = urljoin(url, img['src'])
                    image_urls.append(absolute_url)
        
        # ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¯ãƒªãƒ‹ãƒƒã‚¯å°‚ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'frey-a' in domain:
            for img in soup.find_all('img'):
                alt_text = img.get('alt', '')
                if 'ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¯ãƒªãƒ‹ãƒƒã‚¯' in alt_text and 'é™¢ã®é™¢å†…é¢¨æ™¯' in alt_text:
                    if img.get('src'):
                        absolute_url = urljoin(url, img['src'])
                        image_urls.append(absolute_url)
            
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if '400x265' in src and 'media.frey-a.jp' in src:
                    absolute_url = urljoin(url, src)
                    image_urls.append(absolute_url)
        
        # ãƒªã‚¨ãƒ¼ãƒˆã‚¯ãƒªãƒ‹ãƒƒã‚¯å°‚ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'lietoclinic' in domain:
            for i in range(1, 10):  # ã‚ˆã‚Šå¤šãã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
                main_slider = soup.find(class_=f'js-clinic-mainslick_0{i}')
                if main_slider:
                    first_img = main_slider.find('img')
                    if first_img and first_img.get('src'):
                        absolute_url = urljoin(url, first_img['src'])
                        image_urls.append(absolute_url)
        
        # ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ¼ã‚¹ã‚­ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯å°‚ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'beautyskinclinic' in domain:
            for img in soup.find_all('img'):
                alt_text = img.get('alt', '')
                src = img.get('src', '')
                if 'ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ¼ã‚¹ã‚­ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯' in alt_text and 'é™¢' in alt_text and src.endswith('.webp'):
                    absolute_url = urljoin(url, src)
                    image_urls.append(absolute_url)
        
        # DIOã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'dioclinic' in domain:
            clinic_divs = soup.find_all('div', class_='p-clinic__item--img')
            for div in clinic_divs:
                img = div.find('img')
                if img and img.get('src'):
                    absolute_url = urljoin(url, img['src'])
                    if '/wp-content/uploads/' in absolute_url:
                        image_urls.append(absolute_url)
        
        # ã‚¨ãƒŸãƒŠãƒ«ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        elif 'eminal-clinic' in domain:
            clinic_imgs = soup.find_all('img', class_='p-clinic__clinic-card-img')
            for img in clinic_imgs:
                if img.get('src'):
                    absolute_url = urljoin(url, img['src'])
                    image_urls.append(absolute_url)
        
        # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸Šè¨˜ã«è©²å½“ã—ãªã„å ´åˆï¼‰
        else:
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if any(keyword in src.lower() for keyword in ['clinic', 'store', 'shop', 'facility']):
                    absolute_url = urljoin(url, src)
                    if not any(exclude in absolute_url for exclude in ['logo', 'icon', 'banner']):
                        image_urls.append(absolute_url)
        
        # é‡è¤‡å‰Šé™¤
        image_urls = list(set(image_urls))
        
        # ç”»åƒå½¢å¼ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        valid_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp')
        filtered_urls = [url for url in image_urls if any(url.lower().endswith(ext) for ext in valid_extensions)]
        
        return jsonify({
            'success': True,
            'count': len(filtered_urls),
            'urls': filtered_urls[:20]  # æœ€å¤§20å€‹ã¾ã§è¡¨ç¤º
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/health')
def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({'status': 'ok'})

@app.route('/api/proxy-image', methods=['POST'])
def proxy_image():
    """ç”»åƒã‚’ãƒ—ãƒ­ã‚­ã‚·ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        data = request.json
        image_url = data.get('url')
        
        if not image_url:
            return jsonify({'success': False, 'error': 'URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # ç”»åƒã‚’å–å¾—
        response = requests.get(image_url, headers=headers, timeout=8)
        response.raise_for_status()
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        import base64
        image_base64 = base64.b64encode(response.content).decode('utf-8')
        
        # Content-Typeã‚’åˆ¤å®š
        content_type = response.headers.get('Content-Type', 'image/jpeg')
        
        return jsonify({
            'success': True,
            'data': f'data:{content_type};base64,{image_base64}',
            'filename': image_url.split('/')[-1]
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

app = app